ğŸš€ Multimodal GPT-OSS Vision System
ğŸŒ Extensible to ISRO Earth Observation (EO) Data

An AI-powered multimodal system that augments OpenAI GPT-OSS with vision understanding to analyze satellite imagery, perform visual reasoning, and generate human-readable scientific reports.
Built to support image captioning, visual Q&A, change detection, and EO data analysis.

ğŸ”´ Live Demo

ğŸ‘‰ Deployment URL
ğŸŒ https://studio-979o.onrender.com

ğŸ‘‰ GitHub Repository
ğŸ“¦ https://github.com/SaiPriya0606/studio

ğŸ§­ Application Flow

1ï¸âƒ£ User opens the web application
2ï¸âƒ£ Navigates to Dashboard Modules
3ï¸âƒ£ Uploads / analyzes visual or EO-based inputs
4ï¸âƒ£ AI performs:

Vision understanding

Multimodal reasoning

Report synthesis
5ï¸âƒ£ System generates structured natural-language outputs

ğŸŒ Routes
Route	Description
/	Landing page
/dashboard	Main AI dashboard
/dashboard/eo-analysis	EO data analysis
/dashboard/change-detection	Temporal image comparison
/dashboard/captioning	Image captioning
/dashboard/vqa	Visual Question Answering
/dashboard/reports	Scientific report generation
âœ¨ Key Features
ğŸ–¼ï¸ Multimodal Vision

Image captioning

Visual Question Answering (VQA)

Vision + language alignment

ğŸŒ ISRO EO Data Use-Cases

Land-cover interpretation

Environmental monitoring

Change detection across time-series imagery

ğŸ§  AI Reasoning

Multimodal instruction following

Natural language explanations grounded in visuals

Scientific & executive-level report synthesis

ğŸ“„ Report Generator

ISO-style structured reports

Human-readable summaries

EO evidence-based reasoning

ğŸ§ª How Reviewers Can Test

1ï¸âƒ£ Open the deployed link
2ï¸âƒ£ Go to Dashboard â†’ Any Module
3ï¸âƒ£ Try:

Captioning an image

Asking questions about visual inputs

Generating a report
4ï¸âƒ£ Observe:

Response accuracy

Multimodal reasoning

UI performance

âš ï¸ No local setup required for evaluation

ğŸ› ï¸ Tech Stack
Frontend

Next.js 15 (App Router)

React 19

Tailwind CSS

Radix UI

AI & Multimodal

Genkit

Google Gemini (Vision + Text)

Visionâ€“Language Alignment Pipeline

Backend & Tooling

Node.js

TypeScript

Deployment

Render (Production)

GitHub (Source Control)

âš™ï¸ Environment Variables
GEMINI_API_KEY=your_google_gemini_api_key

ğŸ” How to Check Environment Variables

Render â†’ Service â†’ Environment â†’ Environment Variables

Firebase Studio AI â†’ Project Settings â†’ Secrets

Local â†’ .env file or echo $GEMINI_API_KEY

âœ… Only Gemini API Key is used

ğŸ§© Project Structure (High-Level)
studio/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â””â”€â”€ page.tsx
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ai/
â”‚   â””â”€â”€ hooks/
â”œâ”€â”€ public/
â”œâ”€â”€ package.json
â”œâ”€â”€ next.config.js
â””â”€â”€ README.md

ğŸš€ Local Setup (Optional)
git clone https://github.com/SaiPriya0606/studio.git
cd studio
npm install
export GEMINI_API_KEY=your_api_key
npm run dev


Open ğŸ‘‰ http://localhost:3000

ğŸ” Reviewer Transparency

Firebase Studio AI is used only as a development environment

No Firebase-specific runtime dependency

Final evaluation depends on:

GitHub repository

Render deployment

API key usage is standard & visible

ğŸ‘¨â€ğŸ’» Author

G. Sai Priya

ğŸ”— GitHub: https://github.com/SaiPriya0606

ğŸŒ Deployment: https://studio-979o.onrender.com

â­ If you liked this project, donâ€™t forget to star the repo!

ğŸ“„ License

This project is licensed under the MIT License
