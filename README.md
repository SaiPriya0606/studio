# ğŸš€ Multimodal GPT-OSS Vision System

### ğŸŒ Extensible to ISRO Earth Observation (EO) Data

An AI-powered multimodal system that augments **OpenAI GPT-OSS** with **vision understanding** to analyze satellite imagery, perform visual reasoning, and generate **human-readable scientific reports**.  
Built to support **image captioning, visual question answering (VQA), change detection, and EO data analysis**.

---

## ğŸ”´ Live Demo

### ğŸŒ Deployment
ğŸ‘‰ https://studio-979o.onrender.com  

### ğŸ“¦ GitHub Repository
ğŸ‘‰ https://github.com/SaiPriya0606/studio  

---

## ğŸ§­ Application Flow

1ï¸âƒ£ User opens the web application  
2ï¸âƒ£ Navigates to **Dashboard Modules**  
3ï¸âƒ£ Provides visual / EO-based inputs  
4ï¸âƒ£ AI performs:
- Vision understanding  
- Multimodal reasoning  
- Scientific report synthesis  
5ï¸âƒ£ System generates **structured natural-language outputs**

---

## ğŸŒ Routes

| Route | Description |
|------|------------|
| `/` | Landing page |
| `/dashboard` | Main AI dashboard |
| `/dashboard/eo-analysis` | EO data analysis |
| `/dashboard/change-detection` | Temporal image comparison |
| `/dashboard/captioning` | Image captioning |
| `/dashboard/vqa` | Visual Question Answering |
| `/dashboard/reports` | Scientific report generation |

---

## âœ¨ Key Features

### ğŸ–¼ï¸ Multimodal Vision
- Image captioning  
- Visual Question Answering (VQA)  
- Visionâ€“language embedding alignment  

### ğŸŒ ISRO EO Data Use-Cases
- Land-cover interpretation  
- Environmental monitoring  
- Change detection using time-series imagery  

### ğŸ§  AI Reasoning
- Multimodal instruction following  
- Visual evidenceâ€“grounded explanations  
- Scientific & executive-level report generation  

### ğŸ“„ Report Generator
- Structured ISO-style reports  
- Human-readable summaries  
- EO dataâ€“backed reasoning  

---

## ğŸ§ª How Reviewers Can Test

1ï¸âƒ£ Open the deployment link  
2ï¸âƒ£ Navigate to **Dashboard â†’ Any Module**  
3ï¸âƒ£ Try:
- Image captioning  
- Visual Q&A  
- Report generation  
4ï¸âƒ£ Observe:
- Accuracy of responses  
- Multimodal reasoning quality  
- UI responsiveness  

âš ï¸ **No local setup required for evaluation**

---

## ğŸ› ï¸ Tech Stack

### Frontend
- Next.js 15 (App Router)
- React 19
- Tailwind CSS
- Radix UI

### AI & Multimodal
- Genkit
- Google Gemini (Vision + Text)
- Visionâ€“Language Alignment Pipeline

### Backend & Tooling
- Node.js
- TypeScript

### Deployment
- Render (Production)
- GitHub (Source Control)

---

## âš™ï¸ Environment Variables


GEMINI_API_KEY=your_google_gemini_api_key
ğŸ” How to Check Environment Variables
Render â†’ Service â†’ Environment â†’ Environment Variables

Firebase Studio AI â†’ Project Settings â†’ Secrets

Local â†’ .env file or echo $GEMINI_API_KEY

âœ… Only Gemini API Key is used

## ğŸ§© Project Structure (High-Level)
studio/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â””â”€â”€ page.tsx
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ ai/
â”‚   â””â”€â”€ hooks/
â”œâ”€â”€ public/
â”œâ”€â”€ package.json
â”œâ”€â”€ next.config.js
â””â”€â”€ README.md

## ğŸš€ Local Setup (Optional)
git clone https://github.com/SaiPriya0606/studio.git
cd studio
npm install
export GEMINI_API_KEY=your_api_key
npm run dev
Open ğŸ‘‰ http://localhost:3000

##  ğŸ” Reviewer Transparency
Firebase Studio AI was used only as a development environment

No Firebase dependency in production runtime

Final evaluation relies on:

GitHub repository

Render deployment

API key usage is standard and configurable

### 
ğŸ‘¨â€ğŸ’» Author
G. Sai Priya

ğŸ”— GitHub: https://github.com/SaiPriya0606
ğŸŒ Deployment: https://studio-979o.onrender.com

â­ If you liked this project, donâ€™t forget to star the repository!

ğŸ“„ License
This project is licensed under the MIT License.
